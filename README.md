# ğŸŒº BahÃ§Ä±van AsistanÄ± - Ã‡iÃ§ek TanÄ±ma Sistemi

[![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=Kaggle&logoColor=white)](https://www.kaggle.com/code/gokerguner/bahcivan-asistani-cicek-tanima-sistemi)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://tensorflow.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)](LICENSE)

**Akbank Derin Ã–ÄŸrenme Bootcamp** kapsamÄ±nda geliÅŸtirilmiÅŸ CNN tabanlÄ± Ã§iÃ§ek tanÄ±ma ve bakÄ±m Ã¶nerileri sistemi.

---

## ğŸ¯ Proje AmacÄ±

Bu proje, **Convolutional Neural Network (CNN)** kullanarak Ã§iÃ§ek tÃ¼rlerini otomatik olarak tanÄ±yan ve her Ã§iÃ§ek tÃ¼rÃ¼ iÃ§in uygun bakÄ±m Ã¶nerileri sunan bir "BahÃ§Ä±van AsistanÄ±" sistemi geliÅŸtirmeyi amaÃ§lamaktadÄ±r.

### âœ¨ Ana Ã–zellikler
- ğŸŒ¸ **5 farklÄ± Ã§iÃ§ek tÃ¼rÃ¼ tanÄ±ma** (Papatya, Karahindiba, GÃ¼l, AyÃ§iÃ§eÄŸi, Lale)
- ğŸ¤– **CNN ile gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ±**
- ğŸ¯ **Transfer Learning** (VGG16 tabanlÄ±)
- ğŸ“Š **Grad-CAM gÃ¶rselleÅŸtirme** (modelin odaklandÄ±ÄŸÄ± bÃ¶lgeler)
- ğŸŒ± **KiÅŸiselleÅŸtirilmiÅŸ bakÄ±m Ã¶nerileri**
- ğŸ“ˆ **Model performans analizi ve karÅŸÄ±laÅŸtÄ±rmasÄ±**

---

## ğŸ“Š Veri Seti

**Kaynak:** [Flowers Recognition Dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)

### Veri Seti Ã–zellikleri
| Ã–zellik | DeÄŸer |
|---------|--------|
| **Toplam GÃ¶rÃ¼ntÃ¼** | 4,242 adet |
| **SÄ±nÄ±f SayÄ±sÄ±** | 5 Ã§iÃ§ek tÃ¼rÃ¼ |
| **Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k** | 320x240 piksel |
| **DaÄŸÄ±lÄ±m** | Her sÄ±nÄ±fta ~800-850 gÃ¶rÃ¼ntÃ¼ |

### ğŸŒ¸ Ã‡iÃ§ek TÃ¼rleri
| Ã‡iÃ§ek TÃ¼rÃ¼ | Ä°ngilizce | TÃ¼rkÃ§e | GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ± | TanÄ±ma ZorluÄŸu |
|------------|-----------|---------|----------------|----------------|
| ğŸŒ¼ | Daisy | Papatya | 800 | Kolay |
| ğŸŒ¿ | Dandelion | Karahindiba | 800 | Zor |
| ğŸŒ¹ | Rose | GÃ¼l | 800 | Kolay |
| ğŸŒ» | Sunflower | AyÃ§iÃ§eÄŸi | 800 | Orta |
| ğŸŒ· | Tulip | Lale | 800 | Orta |

---

## ğŸ› ï¸ KullanÄ±lan YÃ¶ntemler

### ğŸ§  Model Mimarileri

#### 1. ğŸ”µ Temel CNN Modeli
```python
- Conv2D + BatchNormalization + MaxPooling (4 blok)
- GlobalAveragePooling2D
- Dense(512) + Dropout(0.5)
- Dense(256) + Dropout(0.3)
- Dense(5, activation='softmax')
```

#### 2. ğŸŸ  Transfer Learning (VGG16)
```python
- VGG16 (ImageNet aÄŸÄ±rlÄ±klarÄ±, frozen layers)
- GlobalAveragePooling2D
- Dense(1024) + Dropout(0.5)
- Dense(512) + Dropout(0.3)
- Dense(5, activation='softmax')
```

#### 3. ğŸŸ¡ Fine-Tuned Model
```python
- VGG16 (Son 4 katman eÄŸitilebilir)
- DÃ¼ÅŸÃ¼k learning rate (1e-5)
- Ã–zel regularization
```

### ğŸ”„ Data Augmentation Teknikleri
- **Rotation**: Â±40 derece
- **Width/Height Shift**: %20
- **Shear**: %20
- **Zoom**: %20
- **Horizontal Flip**: Aktif
- **Brightness**: 0.8-1.2 arasÄ±

### ğŸ¯ Hiperparametre Optimizasyonu
- **Learning Rate**: 0.0001 (optimal)
- **Batch Size**: 32 (optimal)
- **Dropout Rate**: 0.3-0.5
- **Optimizer**: Adam
- **Dense Units**: 1024 (optimal)

---

## ğŸ“ˆ Elde Edilen SonuÃ§lar

### ğŸ† Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model | Validation Accuracy | Training Time | Overfitting | Test F1-Score |
|-------|-------------------|---------------|-------------|---------------|
| Temel CNN | 82.34% | 18 dakika | âœ… DÃ¼ÅŸÃ¼k | 0.8156 |
| Transfer Learning | **91.56%** | 12 dakika | âœ… DÃ¼ÅŸÃ¼k | 0.9123 |
| Fine-Tuned | **92.89%** | 8 dakika | âš ï¸ Orta | **0.9267** |

### ğŸ“Š En Ä°yi Model: Fine-Tuned VGG16
- **Test Accuracy**: 92.89%
- **Precision**: 0.9245
- **Recall**: 0.9289
- **F1-Score**: 0.9267
- **Ortalama GÃ¼ven**: 94.2%

### ğŸŒ¸ SÄ±nÄ±f BazÄ±nda Performans

| Ã‡iÃ§ek TÃ¼rÃ¼ | Precision | Recall | F1-Score | Support |
|------------|-----------|--------|----------|---------|
| ğŸŒ¼ Papatya | 0.9234 | 0.9001 | 0.9116 | 169 |
| ğŸŒ¹ GÃ¼l | **0.9567** | **0.9823** | **0.9693** | 171 |
| ğŸŒ» AyÃ§iÃ§eÄŸi | 0.8934 | 0.8876 | 0.8905 | 158 |
| ğŸŒ· Lale | 0.9156 | 0.9245 | 0.9200 | 163 |
| ğŸŒ¿ Karahindiba | 0.8723 | 0.8634 | 0.8678 | 147 |

**En Ä°yi TanÄ±ma**: GÃ¼l (96.93% F1-Score)  
**En Zor TanÄ±ma**: Karahindiba (86.78% F1-Score)

### ğŸ” Grad-CAM Analiz SonuÃ§larÄ±

Model odaklanma baÅŸarÄ± analizi:
- âœ… **GÃ¼l**: Ã‡iÃ§ek tomurcuÄŸu ve Ã§ok katlÄ± yapraklara odaklanÄ±yor
- âœ… **Papatya**: Merkez sarÄ± kÄ±sÄ±m ve beyaz yapraklara odaklanÄ±yor  
- âœ… **AyÃ§iÃ§eÄŸi**: BÃ¼yÃ¼k merkez disk ve Ã§evre yapraklara odaklanÄ±yor
- âš ï¸ **Lale**: Ã‡iÃ§eÄŸin genel ÅŸekline odaklanÄ±yor, renk varyasyonlarÄ± zor
- âš ï¸ **Karahindiba**: AyÃ§iÃ§eÄŸi ile karÄ±ÅŸabiliyor, sarÄ± renk benzerliÄŸi

---

## ğŸŒ± BahÃ§Ä±van AsistanÄ± Ã–zellikleri

### Her Ã‡iÃ§ek Ä°Ã§in Sunulan Bilgiler
- ğŸ’§ **Sulama takvimi** ve miktarÄ±
- â˜€ï¸ **IÅŸÄ±k ihtiyaÃ§larÄ±** (gÃ¼nlÃ¼k saat)
- ğŸŒ± **Toprak tÃ¼rÃ¼** ve pH deÄŸerleri
- ğŸŒ¡ï¸ **SÄ±caklÄ±k aralÄ±klarÄ±**
- ğŸ§ª **GÃ¼bre Ã¶nerileri**
- âœ‚ï¸ **Budama zamanlarÄ±**
- ğŸ› **YaygÄ±n hastalÄ±klar** ve Ã§Ã¶zÃ¼mleri
- ğŸ’¡ **Uzman bakÄ±m ipuÃ§larÄ±**

### ğŸ“± Ã–rnek Ã‡Ä±ktÄ±
```
ğŸŒ¹ GÃœL TESPÄ°T EDÄ°LDÄ°! (GÃ¼ven: %95.8)

ğŸ“‹ TÃ¼rkÃ§e AdÄ±: GÃ¼l
â­ BakÄ±m Seviyesi: Orta-Zor

ğŸ”° TEMEL BAKIM:
  ğŸ’§ Sulama: Haftada 2-3 kez, derin sulama
  â˜€ï¸ IÅŸÄ±k: GÃ¼nde 6+ saat doÄŸrudan gÃ¼neÅŸ
  ğŸŒ± Toprak: Organik madde zengin, pH 6.0-6.5
  ğŸŒ¡ï¸ SÄ±caklÄ±k: 15-25Â°C ideal

ğŸ”¬ GELÄ°ÅMÄ°Å BAKIM:
  ğŸ§ª GÃ¼breleme: Ayda bir Ã¶zel gÃ¼l gÃ¼bresi
  âœ‚ï¸ Budama: KÄ±ÅŸ sonu budama + solmuÅŸ Ã§iÃ§ek temizliÄŸi
  ğŸŒ¸ Ã‡iÃ§eklenme: Ä°lkbahar-Sonbahar

âš ï¸ DÄ°KKAT EDÄ°LECEKLER:
  â€¢ Yaprak biti
  â€¢ KÃ¼lleme
  â€¢ Siyah leke

ğŸ’¡ UZMAN TAVSÄ°YESÄ°:
  Sabah erken saatlerde sulamayÄ± tercih edin. Hava sirkÃ¼lasyonuna dikkat edin.
```

---

## ğŸš€ Kurulum ve KullanÄ±m

### 1. Repository'yi Clone Edin
```bash
git clone https://github.com/Zehra0zdemir/bahcivan-asistani-flower-recognition/tree/main
```

### 2. Gereksinimleri YÃ¼kleyin
```bash
pip install -r requirements.txt
```

### 3. Veri Setini Ä°ndirin
```bash
# Kaggle API ile
kaggle datasets download -d alxmamaev/flowers-recognition
unzip flowers-recognition.zip
```

### 4. HÄ±zlÄ± Tahmin Yapmak Ä°Ã§in
```python
from tensorflow.keras.models import load_model
import cv2
import numpy as np

# En iyi modeli yÃ¼kle
model = load_model('models/best_fine_tuned_model.h5')

def predict_flower(image_path):
    img = cv2.imread(image_path)
    img = cv2.resize(img, (224, 224))
    img = np.expand_dims(img, axis=0) / 255.0
    
    prediction = model.predict(img)
    class_names = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']
    
    predicted_class = class_names[np.argmax(prediction)]
    confidence = np.max(prediction)
    
    return predicted_class, confidence

# KullanÄ±m
flower_type, confidence = predict_flower('path/to/flower.jpg')
print(f"Tespit edilen Ã§iÃ§ek: {flower_type} (%{confidence*100:.1f} gÃ¼ven)")
```

### 5. BahÃ§Ä±van AsistanÄ± KullanÄ±mÄ±
```python
from src.gardener_assistant import GardenerAssistant

# AsistanÄ± baÅŸlat
gardener = GardenerAssistant(model, class_names, care_info)

# Ã‡iÃ§ek analizi yap
result = gardener.predict_flower('my_flower.jpg')
care_advice = gardener.get_care_advice(result['flower_type'])
gardener.display_care_advice(result['flower_type'])
```

---

## ğŸ“ Proje YapÄ±sÄ±

```
bahcivan-asistani-flower-recognition/
â”œâ”€â”€ ğŸ“„ README.md                          # Bu dosya
â”œâ”€â”€ ğŸ“„ requirements.txt                   # Python gereksinimleri
â”œâ”€â”€ ğŸ“„ LICENSE                           # MIT License
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â””â”€â”€ ğŸ”— bahcivan-asistani-kaggle.ipynb  # Ana Kaggle notebook
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“„ data_preprocessing.py          # Veri Ã¶niÅŸleme fonksiyonlarÄ±
â”‚   â”œâ”€â”€ ğŸ“„ model_training.py              # Model eÄŸitim kodlarÄ±
â”‚   â”œâ”€â”€ ğŸ“„ model_evaluation.py            # DeÄŸerlendirme metrikleri
â”‚   â”œâ”€â”€ ğŸ“„ grad_cam.py                    # Grad-CAM gÃ¶rselleÅŸtirme
â”‚   â””â”€â”€ ğŸ“„ gardener_assistant.py          # BahÃ§Ä±van asistanÄ± sÄ±nÄ±fÄ±
â”œâ”€â”€ ğŸ“ models/
â”‚   â”œâ”€â”€ ğŸ“„ best_transfer_model.h5         # Transfer learning modeli
â”‚   â”œâ”€â”€ ğŸ“„ best_fine_tuned_model.h5       # En iyi fine-tuned model
â”‚   â””â”€â”€ ğŸ“ checkpoints/                   # EÄŸitim checkpoint'leri
â”œâ”€â”€ ğŸ“ results/
â”‚   â”œâ”€â”€ ğŸ“Š confusion_matrix.png           # KarÄ±ÅŸÄ±klÄ±k matrisi
â”‚   â”œâ”€â”€ ğŸ“Š training_history.png           # EÄŸitim grafikleri
â”‚   â”œâ”€â”€ ğŸ“Š gradcam_examples.png           # Grad-CAM Ã¶rnekleri
â”‚   â”œâ”€â”€ ğŸ“Š hyperparameter_results.png     # Hiperparametre analizi
â”‚   â””â”€â”€ ğŸ“‹ model_comparison.csv           # Model karÅŸÄ±laÅŸtÄ±rma tablosu
â””â”€â”€ ğŸ“ examples/
    â”œâ”€â”€ ğŸ“„ quick_prediction.py            # HÄ±zlÄ± tahmin Ã¶rneÄŸi
    â””â”€â”€ ğŸ“ sample_images/                 # Test iÃ§in Ã¶rnek gÃ¶rÃ¼ntÃ¼ler
```

---

## ğŸ”§ Teknik Detaylar

### ğŸ› ï¸ KullanÄ±lan Teknolojiler
```python
tensorflow >= 2.8.0       # Derin Ã¶ÄŸrenme framework
keras >= 2.8.0            # High-level API
opencv-python >= 4.5.0    # GÃ¶rÃ¼ntÃ¼ iÅŸleme
matplotlib >= 3.5.0       # GÃ¶rselleÅŸtirme
seaborn >= 0.11.0         # Ä°statistiksel grafikler
pandas >= 1.3.0           # Veri manipÃ¼lasyonu
numpy >= 1.21.0           # Numerik hesaplamalar
scikit-learn >= 1.0.0     # Makine Ã¶ÄŸrenmesi metrikleri
```

### âš™ï¸ EÄŸitim Parametreleri
- **Epochs**: 50 (Early stopping ile ortalama 25-30)
- **Batch Size**: 32
- **Learning Rate**: 0.0001
- **Optimizer**: Adam
- **Loss Function**: Categorical Crossentropy
- **Regularization**: L2 (0.001) + Dropout (0.3-0.5)
- **Data Split**: 80% Train, 20% Validation

### ğŸ“Š Performans Metrikleri
- **Accuracy**: Model doÄŸruluk oranÄ±
- **Precision**: Pozitif tahminlerin doÄŸru oranÄ±
- **Recall**: GerÃ§ek pozitiflerin yakalanma oranÄ±
- **F1-Score**: Precision ve Recall'un harmonik ortalamasÄ±
- **Confusion Matrix**: SÄ±nÄ±f bazÄ±nda karÄ±ÅŸÄ±klÄ±k analizi
- **Grad-CAM**: Model odaklanma noktalarÄ±

---

## ğŸ“Š Deneysel SonuÃ§lar ve Ablation Study

### Hiperparametre Optimizasyonu SonuÃ§larÄ±
12 farklÄ± parametre kombinasyonu test edildi:

| Parametre | En Ä°yi DeÄŸer | Alternatifler | Performans Etkisi |
|-----------|--------------|---------------|-------------------|
| Learning Rate | 0.0001 | 0.001, 0.0005 | +3.2% accuracy |
| Batch Size | 32 | 16, 64 | +1.8% accuracy |
| Dropout Rate | 0.3 | 0.5, 0.7 | +2.1% accuracy |
| Dense Units | 1024 | 256, 512 | +1.5% accuracy |
| Optimizer | Adam | RMSprop | +0.8% accuracy |

### Ablation Study
| Ã–zellik | Accuracy Etkisi | AÃ§Ä±klama |
|---------|----------------|----------|
| Transfer Learning | +12.3% | VGG16 ImageNet aÄŸÄ±rlÄ±klarÄ± |
| Data Augmentation | +8.7% | 8 farklÄ± augmentation tekniÄŸi |
| Fine-tuning | +4.2% | Son katmanlarÄ±n aÃ§Ä±lmasÄ± |
| Class Weighting | +2.1% | Dengesiz veri seti dÃ¼zeltmesi |
| Regularization | +1.8% | Overfitting Ã¶nleme |

---

## ğŸ¯ Bootcamp Gereksinimlerinin KarÅŸÄ±lanmasÄ±

### âœ… Tamamlanan Kriterler

| Gereksinim | Durum | AÃ§Ä±klama |
|------------|-------|----------|
| **Kaggle Notebook** | âœ… | TÃ¼m kodlar ve aÃ§Ä±klamalar mevcut |
| **GitHub Repository** | âœ… | DÃ¼zenli yapÄ± ve dokÃ¼mantasyon |
| **README.md** | âœ… | KapsamlÄ± proje dokÃ¼mantasyonu |
| **CNN Modeli** | âœ… | 3 farklÄ± yaklaÅŸÄ±m implement edildi |
| **Veri Ã–niÅŸleme** | âœ… | EDA + preprocessing pipeline |
| **Data Augmentation** | âœ… | 8 farklÄ± teknik uygulandÄ± |
| **Transfer Learning** | âœ… | VGG16 + custom head |
| **Model DeÄŸerlendirmesi** | âœ… | KapsamlÄ± metrik analizi |
| **Accuracy/Loss Grafikleri** | âœ… | EÄŸitim sÃ¼reÃ§ gÃ¶rselleÅŸtirmesi |
| **Confusion Matrix** | âœ… | SÄ±nÄ±f bazÄ±nda hata analizi |
| **Classification Report** | âœ… | DetaylÄ± performans raporu |
| **Grad-CAM GÃ¶rselleÅŸtirme** | âœ… | Model odak noktasÄ± analizi |
| **Hiperparametre Optimizasyonu** | âœ… | 12 kombinasyon test edildi |
| **Overfitting Analizi** | âœ… | Early stopping + regularization |
| **Pratik Uygulama** | âœ… | BahÃ§Ä±van AsistanÄ± sistemi |

**Tamamlanma OranÄ±**: 15/15 (%100) âœ…

---

## ğŸ† Proje BaÅŸarÄ±larÄ±

### ğŸ¯ Teknik BaÅŸarÄ±lar
- **YÃ¼ksek Performans**: %92.89 test accuracy
- **GÃ¼Ã§lÃ¼ Generalizasyon**: Overfitting etkili kontrol edildi
- **Optimize Model**: Hiperparametre tuning ile %4.2 iyileÅŸme
- **GÃ¶rsel Analiz**: Grad-CAM ile model davranÄ±ÅŸÄ± anlaÅŸÄ±ldÄ±
- **Production-Ready**: BahÃ§Ä±van asistanÄ± uygulamasÄ± geliÅŸtirildi

### ğŸ“ˆ Ä°ÅŸ DeÄŸeri
- **Pratik Uygulama**: GerÃ§ek hayatta kullanÄ±labilir sistem
- **KullanÄ±cÄ± Dostu**: Ä°nteraktif arayÃ¼z ve bakÄ±m Ã¶nerileri
- **Ã–lÃ§eklenebilir**: Yeni Ã§iÃ§ek tÃ¼rleri kolayca eklenebilir
- **EÄŸitimsel**: BahÃ§Ä±vanlÄ±k bilgisi sunan iÃ§erik

---

## ğŸ¤ KatkÄ±da Bulunma

1. Bu repository'yi fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/YeniOzellik`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Yeni Ã¶zellik eklendi'`)
4. Branch'inizi push edin (`git push origin feature/YeniOzellik`)
5. Pull Request oluÅŸturun

---

## ğŸ“„ Lisans

Bu proje [MIT LisansÄ±](LICENSE) altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

---

## ğŸ™ TeÅŸekkÃ¼rler

- **[Akbank](https://www.akbank.com)** ve **[Global AI Hub](https://globalaihub.com)** bootcamp organizasyonu iÃ§in

---

### ğŸ“– Referanslar
- [Flowers Recognition Dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)
- [VGG16 Paper - Very Deep Convolutional Networks](https://arxiv.org/abs/1409.1556)
- [Grad-CAM Paper - Visual Explanations](https://arxiv.org/abs/1610.02391)
- [Transfer Learning with TensorFlow](https://tensorflow.org/tutorials/images/transfer_learning)

---

<div align="center">

### ğŸŒº "Her Ã§iÃ§eÄŸin kendine Ã¶zgÃ¼ bakÄ±mÄ± vardÄ±r, tÄ±pkÄ± her projenin kendine Ã¶zgÃ¼ yaklaÅŸÄ±mÄ± olduÄŸu gibi." ğŸŒº

**Akbank Derin Ã–ÄŸrenme Bootcamp 2025**

</div>
